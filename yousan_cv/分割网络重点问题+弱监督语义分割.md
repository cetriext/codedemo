### FCN

- 全卷积网络：没有全连接层

- 分为编码器部分和解码器部分。编码器可以是常见cnn网络，

- 特征融合：浅层特征（局部，精细的特征）+ 深层特征（全局，粗糙，感受野增加）

  图像金字塔（合成强特征）FCN-32s   FCN-16s  FCN-8s  // 步长为32，16，8的特征进行上采样

  FCN-32s---对应pool5   2^5    （pool5后面conv6、7）conv7 的 32倍上采样

  FCN-16s   conv7 的分辨率两倍提升（上采样2倍）+【pool4（conv4）+ 1x1卷积保证通道数一致】，然后16倍上采样

  FCN-8s   FCN-16s16倍上采样之前的两倍上采样 + 【pool3（conv3）+ 1x1卷积保证通道数一致】，然后8倍上采样；这个上采样不学习

- 第一个卷积层使用了较大的填充conv2d（3，64， padding = 100， kernel_size = 3, stride = 1）

- 特征融合之前使用1x1维度变换

- 特征融合要进行裁剪，保证尺度一致 crop层：offset = (original_size - desired_size)/2

- 特征融合之前的上采样层  kernel_size = 4, stride = 2   2倍上采样

- FCN-8s输出层： kernel_size = 16, stride = 8   8倍上采样

- 结论：特征融合有助于改善结果，仅作浅层特征融合是不行的，

### SegNet

- 更加对称的结构，所有卷积都是64个通道   7x7卷积核  左右都是4层

- 上采样实现：记录池化：最大池化的时候记录保留的值的位置（每个区域的最大值）

  上采样的时候还原这些位置

- 上采样没有学习参数，需要占据存储空间（位置）
- 逐层训练：首先训练外层（编码与解码），训练结束后固定，再添加内层训练
- 更深层网络有更少激活，但语义级别更高的特征

### Unet

- 跳层连接，特征图拼接，23层卷积
- 下采样：2x2池化，上采样：2x2反卷积

### 语义分割的关键难题：

- 恢复高分辨率：下采样后特征分辨率变低，cnn具有一定程度的空间不变性

- 膨胀卷积：调整卷积元素之间的距离，使感受野变大  // 串联结构or并联结构

  与大卷积核比较：有更少的卷积参数

  与池化比较：保留了更大的卷积特征图

  与增加网络深度比较：减少计算量

  deeplab v1v2v3+

- 多尺度特征融合

  图像金字塔

  ParseNet

  PSPNet：金字塔池化模块：并联四个尺度的池化，直接上采样到同样大小进行拼接

  RefineNet：类似于unet

- CNN单独预测，但应该考虑像素之间的关系 -->基于CRF的方法

  Grabcut图割：提前画一个框  //DeepLab

### 弱监督语义分割

- 标注耗时

  类别标注< 点point标注、笔触strokes标注< 目标框bounding box

  在以上标注下的分割

- 模型训练初始化

  阈值法：基于类的灰度分布和方差 cv2.threshold(img, thresh, maxVal, type)

  Grabcut: 基于CRF的图割方法，人机交互框选前景，得到确定性背景区域

  CAM：类激活热图，用于可视化模型学习到的信息（通过GAP得到特征图）

  显著性目标检测：基于人眼观察特征区域统计显著目标所在区域（追踪人眼），与类别无关（编解码模型）

- 基于类别信息的模型：

  - 基于CAM和Saliency的模型：使用CAM热图获得种子区域，使用Saliency获得前景标签，使用Guide Labeller获得标签

    CAM：精度高，召回率低——>种子（目标区域）

    使用显著性目标检测数据集的bounding box作为初始化，grabcut分割的结果作为标签，训练一个DeepLab-v2 的ResNet模型：召回率高，可能召回非目标区域

    伪标签的产生：guide labeller 从saliency区域获得标签值

- 基于目标框的模型：BoxSup

  - 基于目标框和*候选*掩膜更新

  - 候选掩膜的生成：selective serach聚类

    基于候选掩膜的标签进行监督学习，基于语义特征挑选更好的候选掩膜，基于一个真值框选择一个候选掩膜，前景取真值框的标签，其他为背景

    候选掩膜的位置和大小在训练过程（候选掩膜的语义标签的学习，选择mask旁边的像素加入扩大掩膜）中不变化

    增加候选掩膜的扰动：从损失最大的k个里面选择mask

    掩膜的优化目标：真值B与候选掩膜S的最小外接矩形的归一化IOU，归一化用标签的分类正确与否-->当语义标签一致时，会选择前景区域越大越好

    分类优化目标：交叉熵损失

