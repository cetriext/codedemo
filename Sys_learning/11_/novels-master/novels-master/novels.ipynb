{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import jieba\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "novel_path = \"E:/Learn/WORD2VEC/金庸小说精校版/\"\n",
    "data_path = \"E:/Learn/WORD2VEC/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1903\n",
      "['乘势', '乘机', '乘胜', '乘虚', '乘隙', '九', '也', '也好', '也就是说', '也是', '也罢', '了', '了解', '争取', '二', '二来', '二话不说', '二话没说', '于', '于是']\n"
     ]
    }
   ],
   "source": [
    "# 加载停用词表\n",
    "stop_words_file = open(data_path + \"stop_words.txt\", 'r')\n",
    "stop_words = list()\n",
    "for line in stop_words_file.readlines():\n",
    "    line = line.strip()   # 去掉每行末尾的换行符\n",
    "    stop_words.append(line)\n",
    "stop_words_file.close()\n",
    "print(len(stop_words))\n",
    "print(stop_words[300:320])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分词前在词库中加入人物名称、武功名称、门派名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1237\n"
     ]
    }
   ],
   "source": [
    "# 导入金庸小说人物\n",
    "people_names_file = open(data_path + \"金庸小说全人物.txt\", 'r')\n",
    "people_names = list()\n",
    "for line in people_names_file.readlines():\n",
    "    line = line.strip()   # 去掉每行末尾的换行符\n",
    "    jieba.add_word(line)\n",
    "    people_names.append(line)\n",
    "stop_words_file.close()\n",
    "print(len(people_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389\n"
     ]
    }
   ],
   "source": [
    "# 导入金庸小说武功\n",
    "kungfu_names_file = open(data_path + \"金庸小说全武功.txt\", 'r')\n",
    "kungfu_names = list()\n",
    "for line in kungfu_names_file.readlines():\n",
    "    line = line.strip()   # 去掉每行末尾的换行符\n",
    "    jieba.add_word(line)\n",
    "    kungfu_names.append(line)\n",
    "stop_words_file.close()\n",
    "print(len(kungfu_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n"
     ]
    }
   ],
   "source": [
    "# 导入金庸小说门派\n",
    "sect_names_file = open(data_path + \"金庸小说全门派.txt\", 'r')\n",
    "sect_names = list()\n",
    "for line in sect_names_file.readlines():\n",
    "    line = line.strip()   # 去掉每行末尾的换行符\n",
    "    jieba.add_word(line)\n",
    "    sect_names.append(line)\n",
    "stop_words_file.close()\n",
    "print(len(sect_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "novel_names = list(os.listdir(novel_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for 书剑恩仇录.txt...\n",
      "书剑恩仇录.txt finished，with 3561 Row\n",
      "----------------------------------------\n",
      "Waiting for 侠客行.txt...\n",
      "侠客行.txt finished，with 3513 Row\n",
      "----------------------------------------\n",
      "Waiting for 倚天屠龙记.txt...\n",
      "倚天屠龙记.txt finished，with 7918 Row\n",
      "----------------------------------------\n",
      "Waiting for 天龙八部.txt...\n",
      "天龙八部.txt finished，with 10947 Row\n",
      "----------------------------------------\n",
      "Waiting for 射雕英雄传.txt...\n",
      "射雕英雄传.txt finished，with 7130 Row\n",
      "----------------------------------------\n",
      "Waiting for 白马啸西风.txt...\n",
      "白马啸西风.txt finished，with 597 Row\n",
      "----------------------------------------\n",
      "Waiting for 碧血剑.txt...\n",
      "碧血剑.txt finished，with 3786 Row\n",
      "----------------------------------------\n",
      "Waiting for 神雕侠侣.txt...\n",
      "神雕侠侣.txt finished，with 6998 Row\n",
      "----------------------------------------\n",
      "Waiting for 笑傲江湖.txt...\n",
      "笑傲江湖.txt finished，with 8550 Row\n",
      "----------------------------------------\n",
      "Waiting for 越女剑.txt...\n",
      "越女剑.txt finished，with 196 Row\n",
      "----------------------------------------\n",
      "Waiting for 连城诀.txt...\n",
      "连城诀.txt finished，with 2207 Row\n",
      "----------------------------------------\n",
      "Waiting for 雪山飞狐.txt...\n",
      "雪山飞狐.txt finished，with 1096 Row\n",
      "----------------------------------------\n",
      "Waiting for 飞狐外传.txt...\n",
      "飞狐外传.txt finished，with 3776 Row\n",
      "----------------------------------------\n",
      "Waiting for 鸳鸯刀.txt...\n",
      "鸳鸯刀.txt finished，with 211 Row\n",
      "----------------------------------------\n",
      "Waiting for 鹿鼎记.txt...\n",
      "鹿鼎记.txt finished，with 11158 Row\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "All finished，with 71644 Row\n"
     ]
    }
   ],
   "source": [
    "seg_novel = []\n",
    "for novel_name in novel_names:\n",
    "    novel = open(novel_path + novel_name, 'r', encoding='utf-8-sig')\n",
    "    print(\"Waiting for {}...\".format(novel_name))\n",
    "    line = novel.readline()\n",
    "    forward_rows = len(seg_novel)\n",
    "    while line:\n",
    "        line_1 = line.strip()\n",
    "        outstr = ''\n",
    "        line_seg = jieba.cut(line_1, cut_all=False)\n",
    "        for word in line_seg:  \n",
    "            if word not in stop_words:\n",
    "                if word != '\\t':\n",
    "                    if word[:2] in people_names:\n",
    "                        word = word[:2]\n",
    "                    outstr += word \n",
    "                    outstr += \" \"\n",
    "        if len(str(outstr.strip())) != 0:\n",
    "            seg_novel.append(str(outstr.strip()).split())\n",
    "        line = novel.readline()\n",
    "    print(\"{} finished，with {} Row\".format(novel_name, (len(seg_novel) - forward_rows)))\n",
    "    print(\"-\" * 40)\n",
    "print(\"-\" * 40)\n",
    "print(\"-\" * 40)\n",
    "print(\"All finished，with {} Row\".format(len(seg_novel)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['郭靖', '黄蓉', '完颜洪烈', '做', '爹爹', '语气', '间', '亲热', '相互', '一眼', '郭靖', '气恼', '难受', '恨不得', '揪住', '问个', '明白']\n",
      "['听', '完颜洪烈', '我大金', '正隆', '年间', '我大', '金主', '金主亮', '见到', '柳永', '这首词', '西湖', '风景', '欣然', '有慕', '派遣', '使者', '南下', '时', '派', '著名', '画工', '摹写', '一幅', '临安', '城', '山水', '图画', '金主', '状貌', '策马', '立在', '临安', '城内', '吴山之', '顶', '金主', '画', '题诗', '万里', '车书', '混同', '江南', '别疆封', '提兵', '百万', '西湖', '吴山', '第一峰', '杨康', '赞道', '豪壮', '气概', '郭靖', '恼怒', '之极', '捏', '手指', '格格直', '响']\n",
      "['完颜洪烈', '叹', '金主亮', '提兵', '南征', '吴山之', '志', '不酬', '这番', '投鞭', '渡江', '豪气', '却是', '做', '子孙', '效法', '扇子', '题诗', '大柄', '在手', '清风', '满天下', '这是', '何等', '志向', '杨康', '吟道', '大柄', '在手', '清风', '满天下', '言下', '甚', '神往', '欧阳锋', '干笑', '数声', '日', '王爷', '大柄', '在手', '吴山之', '志', '定然', '可酬']\n",
      "['完颜洪烈', '悄声', '所说', '耳目众多', '饮酒', '三人', '转过', '话题', '说些', '景物', '见闻', '风土人情']\n",
      "['黄蓉', '郭靖', '边道', '喝得', '酒儿', '偏', '两人', '溜', '出阁', '子', '来到', '后园', '黄蓉', '晃动', '火折', '点燃', '柴房中', '柴草', '四下', '放', '起火']\n",
      "['一刻', '火头', '蹿', '刹那间', '人声鼎沸', '大叫', '走水', '救火', '听', '铜锣', '当当乱', '敲', '黄蓉', '快到', '莫再', '走得', '不知去向', '郭靖', '恨', '恨', '地道', '今晚', '刺杀', '完颜洪烈', '奸贼', '黄蓉', '先', '陪', '师父', '进宫', '大吃一顿', '约', '老顽童', '敌住', '西毒', '对付', '两个', '奸贼', '郭靖', '不错', '两人', '丛中', '挤', '楼前', '恰见', '完颜洪烈', '欧阳锋', '杨康', '三人', '酒楼', '中', '两人远', '穿街过巷', '进', '西', '市场', '冠盖', '居', '客店']\n",
      "['两人', '客店', '外', '良久', '完颜洪烈', '必是', '住', '这家', '店中', '黄蓉', '回去', '待会', '约', '老顽童', '找', '晦气', '回到', '锦华', '居']\n",
      "['未到', '店前', '听', '周伯通', '声音', '大声', '喧嚷', '郭靖', '吓了一跳', '师父', '伤势', '有变', '急步', '上前', '周伯通', '蹲', '地下', '正', '六七个', '孩童', '拌嘴', '店', '门前', '孩童', '掷', '钱', '出发', '暗器', '手法', '大嬴特', '嬴', '孩儿', '耍赖', '不肯', '赔钱', '不依', '吵闹', '黄蓉', '回来', '责骂', '掉头', '进店', '黄蓉', '取出', '面具', '周伯通', '甚', '欢喜', '戴上', '做', '一阵', '判官', '做', '一阵', '小鬼']\n",
      "['黄蓉', '相助', '西毒', '周伯通', '一口', '答应', '放心', '两只手', '两种', '拳法', '斗', '黄蓉', '想起', '当日', '桃花', '岛上', '他怕', '无意', '中', '使出', '九阴真经', '功夫', '自行', '缚住', '双手', '爹爹', '伤', '西毒', '坏', '当年', '师哥', '打过', '真经', '功夫', '伤', '不算', '违了', '师哥', '遗训', '周伯通', '瞪眼', '已练', '不用', '真经', '功夫', '法子']\n",
      "['一日', '中', '洪七公', '心', '早已', '御厨', '之内', '好容易', '挨到', '时分', '郭靖', '负', '洪七公', '四人', '上屋', '径往', '大内', '皇宫', '高出', '民居', '屋瓦', '金光灿烂', '极易', '辨认', '不多时', '四人', '已悄', '没声', '跃进', '宫墙']\n"
     ]
    }
   ],
   "source": [
    "for line in seg_novel[30000:30010]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program\\python\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import gensim.models as w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = w2v.Word2Vec(sentences=seg_novel, size=200, window=5, min_count=5, workers=4, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 寻找相似关系\n",
    "def find_relation(a, b, c):\n",
    "    d, _ = model.most_similar(positive=[c, b], negative=[a])[0]\n",
    "    print (c,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "天地会 陈近南\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program\\python\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "find_relation(\"武当派\",\"张三丰\",\"天地会\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('周芷若', 0.6134092211723328),\n",
       " ('赵敏', 0.5959696769714355),\n",
       " ('小昭', 0.5360002517700195),\n",
       " ('杨逍', 0.5234625935554504),\n",
       " ('波斯', 0.49604594707489014),\n",
       " ('盈盈', 0.4853126108646393),\n",
       " ('东方不败', 0.48061659932136536),\n",
       " ('范遥', 0.4620290696620941),\n",
       " ('韦一笑', 0.4601820111274719),\n",
       " ('殷天正', 0.4529567062854767)]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"张无忌\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(data_path + 'all_skip_gram.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = w2v.Word2Vec.load(data_path + 'all_skip_gram.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6134092\n",
      "0.5959696\n"
     ]
    }
   ],
   "source": [
    "print(model.similarity('张无忌', '周芷若'))\n",
    "print(model.similarity('张无忌', '赵敏'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.most_similar(\"韦小宝\", topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('林朝英', 0.8663322925567627),\n",
       " ('宝典', 0.8595889210700989),\n",
       " ('研习', 0.8348122835159302),\n",
       " ('创制', 0.8294848799705505),\n",
       " ('先天功', 0.8276116251945496),\n",
       " ('医术', 0.827604353427887),\n",
       " ('精研', 0.8269264101982117),\n",
       " ('神通', 0.8256270885467529),\n",
       " ('剑宗', 0.8248381614685059),\n",
       " ('功诀', 0.8226447701454163)]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"王重阳\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36201134\n",
      "0.5046786\n",
      "0.52167255\n",
      "0.47715494\n",
      "0.38285166\n",
      "0.4028411\n",
      "0.40740663\n"
     ]
    }
   ],
   "source": [
    "print(model.similarity('韦小宝', '阿珂'))\n",
    "print(model.similarity('韦小宝', '双儿'))\n",
    "print(model.similarity('韦小宝', '建宁公主'))\n",
    "print(model.similarity('韦小宝', '苏荃'))\n",
    "print(model.similarity('韦小宝', '沐剑屏'))\n",
    "print(model.similarity('韦小宝', '曾柔'))\n",
    "print(model.similarity('韦小宝', '方怡'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'find_relation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-9e1e5970e58d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfind_relation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"杨过\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"小龙女\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"乔峰\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'find_relation' is not defined"
     ]
    }
   ],
   "source": [
    "find_relation(\"杨过\",\"小龙女\",\"乔峰\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
