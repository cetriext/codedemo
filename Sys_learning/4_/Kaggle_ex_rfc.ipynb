{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "functional-taxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", size=14)\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\") #white background style for seaborn plots\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "needed-highland",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(r\"C:\\Users\\20943\\Desktop\\我的坚果云\\Sys_learning\\3_\\titanic\\train.csv\")\n",
    "test_df = pd.read_csv(r\"C:\\Users\\20943\\Desktop\\我的坚果云\\Sys_learning\\3_\\titanic\\test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "desperate-humor",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class BaggingClassifier in module sklearn.ensemble._bagging:\n",
      "\n",
      "class BaggingClassifier(sklearn.base.ClassifierMixin, BaseBagging)\n",
      " |  BaggingClassifier(base_estimator=None, n_estimators=10, *, max_samples=1.0, max_features=1.0, bootstrap=True, bootstrap_features=False, oob_score=False, warm_start=False, n_jobs=None, random_state=None, verbose=0)\n",
      " |  \n",
      " |  A Bagging classifier.\n",
      " |  \n",
      " |  A Bagging classifier is an ensemble meta-estimator that fits base\n",
      " |  classifiers each on random subsets of the original dataset and then\n",
      " |  aggregate their individual predictions (either by voting or by averaging)\n",
      " |  to form a final prediction. Such a meta-estimator can typically be used as\n",
      " |  a way to reduce the variance of a black-box estimator (e.g., a decision\n",
      " |  tree), by introducing randomization into its construction procedure and\n",
      " |  then making an ensemble out of it.\n",
      " |  \n",
      " |  This algorithm encompasses several works from the literature. When random\n",
      " |  subsets of the dataset are drawn as random subsets of the samples, then\n",
      " |  this algorithm is known as Pasting [1]_. If samples are drawn with\n",
      " |  replacement, then the method is known as Bagging [2]_. When random subsets\n",
      " |  of the dataset are drawn as random subsets of the features, then the method\n",
      " |  is known as Random Subspaces [3]_. Finally, when base estimators are built\n",
      " |  on subsets of both samples and features, then the method is known as\n",
      " |  Random Patches [4]_.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <bagging>`.\n",
      " |  \n",
      " |  .. versionadded:: 0.15\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  base_estimator : object, default=None\n",
      " |      The base estimator to fit on random subsets of the dataset.\n",
      " |      If None, then the base estimator is a\n",
      " |      :class:`~sklearn.tree.DecisionTreeClassifier`.\n",
      " |  \n",
      " |  n_estimators : int, default=10\n",
      " |      The number of base estimators in the ensemble.\n",
      " |  \n",
      " |  max_samples : int or float, default=1.0\n",
      " |      The number of samples to draw from X to train each base estimator (with\n",
      " |      replacement by default, see `bootstrap` for more details).\n",
      " |  \n",
      " |      - If int, then draw `max_samples` samples.\n",
      " |      - If float, then draw `max_samples * X.shape[0]` samples.\n",
      " |  \n",
      " |  max_features : int or float, default=1.0\n",
      " |      The number of features to draw from X to train each base estimator (\n",
      " |      without replacement by default, see `bootstrap_features` for more\n",
      " |      details).\n",
      " |  \n",
      " |      - If int, then draw `max_features` features.\n",
      " |      - If float, then draw `max_features * X.shape[1]` features.\n",
      " |  \n",
      " |  bootstrap : bool, default=True\n",
      " |      Whether samples are drawn with replacement. If False, sampling\n",
      " |      without replacement is performed.\n",
      " |  \n",
      " |  bootstrap_features : bool, default=False\n",
      " |      Whether features are drawn with replacement.\n",
      " |  \n",
      " |  oob_score : bool, default=False\n",
      " |      Whether to use out-of-bag samples to estimate\n",
      " |      the generalization error.\n",
      " |  \n",
      " |  warm_start : bool, default=False\n",
      " |      When set to True, reuse the solution of the previous call to fit\n",
      " |      and add more estimators to the ensemble, otherwise, just fit\n",
      " |      a whole new ensemble. See :term:`the Glossary <warm_start>`.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *warm_start* constructor parameter.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      The number of jobs to run in parallel for both :meth:`fit` and\n",
      " |      :meth:`predict`. ``None`` means 1 unless in a\n",
      " |      :obj:`joblib.parallel_backend` context. ``-1`` means using all\n",
      " |      processors. See :term:`Glossary <n_jobs>` for more details.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      Controls the random resampling of the original dataset\n",
      " |      (sample wise and feature wise).\n",
      " |      If the base estimator accepts a `random_state` attribute, a different\n",
      " |      seed is generated for each instance in the ensemble.\n",
      " |      Pass an int for reproducible output across multiple function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  verbose : int, default=0\n",
      " |      Controls the verbosity when fitting and predicting.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  base_estimator_ : estimator\n",
      " |      The base estimator from which the ensemble is grown.\n",
      " |  \n",
      " |  n_features_ : int\n",
      " |      The number of features when :meth:`fit` is performed.\n",
      " |  \n",
      " |  estimators_ : list of estimators\n",
      " |      The collection of fitted base estimators.\n",
      " |  \n",
      " |  estimators_samples_ : list of arrays\n",
      " |      The subset of drawn samples (i.e., the in-bag samples) for each base\n",
      " |      estimator. Each subset is defined by an array of the indices selected.\n",
      " |  \n",
      " |  estimators_features_ : list of arrays\n",
      " |      The subset of drawn features for each base estimator.\n",
      " |  \n",
      " |  classes_ : ndarray of shape (n_classes,)\n",
      " |      The classes labels.\n",
      " |  \n",
      " |  n_classes_ : int or list\n",
      " |      The number of classes.\n",
      " |  \n",
      " |  oob_score_ : float\n",
      " |      Score of the training dataset obtained using an out-of-bag estimate.\n",
      " |      This attribute exists only when ``oob_score`` is True.\n",
      " |  \n",
      " |  oob_decision_function_ : ndarray of shape (n_samples, n_classes)\n",
      " |      Decision function computed with out-of-bag estimate on the training\n",
      " |      set. If n_estimators is small it might be possible that a data point\n",
      " |      was never left out during the bootstrap. In this case,\n",
      " |      `oob_decision_function_` might contain NaN. This attribute exists\n",
      " |      only when ``oob_score`` is True.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.svm import SVC\n",
      " |  >>> from sklearn.ensemble import BaggingClassifier\n",
      " |  >>> from sklearn.datasets import make_classification\n",
      " |  >>> X, y = make_classification(n_samples=100, n_features=4,\n",
      " |  ...                            n_informative=2, n_redundant=0,\n",
      " |  ...                            random_state=0, shuffle=False)\n",
      " |  >>> clf = BaggingClassifier(base_estimator=SVC(),\n",
      " |  ...                         n_estimators=10, random_state=0).fit(X, y)\n",
      " |  >>> clf.predict([[0, 0, 0, 0]])\n",
      " |  array([1])\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  \n",
      " |  .. [1] L. Breiman, \"Pasting small votes for classification in large\n",
      " |         databases and on-line\", Machine Learning, 36(1), 85-103, 1999.\n",
      " |  \n",
      " |  .. [2] L. Breiman, \"Bagging predictors\", Machine Learning, 24(2), 123-140,\n",
      " |         1996.\n",
      " |  \n",
      " |  .. [3] T. Ho, \"The random subspace method for constructing decision\n",
      " |         forests\", Pattern Analysis and Machine Intelligence, 20(8), 832-844,\n",
      " |         1998.\n",
      " |  \n",
      " |  .. [4] G. Louppe and P. Geurts, \"Ensembles on Random Patches\", Machine\n",
      " |         Learning and Knowledge Discovery in Databases, 346-361, 2012.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      BaggingClassifier\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      BaseBagging\n",
      " |      sklearn.ensemble._base.BaseEnsemble\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, base_estimator=None, n_estimators=10, *, max_samples=1.0, max_features=1.0, bootstrap=True, bootstrap_features=False, oob_score=False, warm_start=False, n_jobs=None, random_state=None, verbose=0)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Average of the decision functions of the base classifiers.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The training input samples. Sparse matrices are accepted only if\n",
      " |          they are supported by the base estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : ndarray of shape (n_samples, k)\n",
      " |          The decision function of the input samples. The columns correspond\n",
      " |          to the classes in sorted order, as they appear in the attribute\n",
      " |          ``classes_``. Regression and binary classification are special\n",
      " |          cases with ``k == 1``, otherwise ``k==n_classes``.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict class for X.\n",
      " |      \n",
      " |      The predicted class of an input sample is computed as the class with\n",
      " |      the highest mean predicted probability. If base estimators do not\n",
      " |      implement a ``predict_proba`` method, then it resorts to voting.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The training input samples. Sparse matrices are accepted only if\n",
      " |          they are supported by the base estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : ndarray of shape (n_samples,)\n",
      " |          The predicted classes.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Predict class log-probabilities for X.\n",
      " |      \n",
      " |      The predicted class log-probabilities of an input sample is computed as\n",
      " |      the log of the mean predicted class probabilities of the base\n",
      " |      estimators in the ensemble.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The training input samples. Sparse matrices are accepted only if\n",
      " |          they are supported by the base estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : ndarray of shape (n_samples, n_classes)\n",
      " |          The class log-probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute :term:`classes_`.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Predict class probabilities for X.\n",
      " |      \n",
      " |      The predicted class probabilities of an input sample is computed as\n",
      " |      the mean predicted class probabilities of the base estimators in the\n",
      " |      ensemble. If base estimators do not implement a ``predict_proba``\n",
      " |      method, then it resorts to voting and the predicted class probabilities\n",
      " |      of an input sample represents the proportion of estimators predicting\n",
      " |      each class.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The training input samples. Sparse matrices are accepted only if\n",
      " |          they are supported by the base estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : ndarray of shape (n_samples, n_classes)\n",
      " |          The class probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute :term:`classes_`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of ``self.predict(X)`` wrt. `y`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseBagging:\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Build a Bagging ensemble of estimators from the training\n",
      " |         set (X, y).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The training input samples. Sparse matrices are accepted only if\n",
      " |          they are supported by the base estimator.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          The target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights. If None, then samples are equally weighted.\n",
      " |          Note that this is supported only if the base estimator supports\n",
      " |          sample weighting.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from BaseBagging:\n",
      " |  \n",
      " |  estimators_samples_\n",
      " |      The subset of drawn samples for each base estimator.\n",
      " |      \n",
      " |      Returns a dynamically generated list of indices identifying\n",
      " |      the samples used for fitting each member of the ensemble, i.e.,\n",
      " |      the in-bag samples.\n",
      " |      \n",
      " |      Note: the list is re-created at each call to the property in order\n",
      " |      to reduce the object memory footprint by not storing the sampling\n",
      " |      data. Thus fetching the property may be slower than expected.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.ensemble._base.BaseEnsemble:\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |      Return the index'th estimator in the ensemble.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Return iterator over estimators in the ensemble.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Return the number of estimators in the ensemble.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from sklearn.ensemble._base.BaseEnsemble:\n",
      " |  \n",
      " |  __annotations__ = {'_required_parameters': typing.List[str]}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(BaggingClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "surprising-encyclopedia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "continuing-imaging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>TravelAlone</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>IsMinor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived   Age     Fare  TravelAlone  Pclass_1  Pclass_2  Pclass_3  \\\n",
       "0         0  22.0   7.2500            0         0         0         1   \n",
       "1         1  38.0  71.2833            0         1         0         0   \n",
       "2         1  26.0   7.9250            1         0         0         1   \n",
       "3         1  35.0  53.1000            0         1         0         0   \n",
       "4         0  35.0   8.0500            1         0         0         1   \n",
       "\n",
       "   Embarked_C  Embarked_Q  Embarked_S  Sex_male  IsMinor  \n",
       "0           0           0           1         1        0  \n",
       "1           1           0           0         0        0  \n",
       "2           0           0           1         0        0  \n",
       "3           0           0           1         0        0  \n",
       "4           0           0           1         1        0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_df.copy()\n",
    "train_data[\"Age\"].fillna(train_df[\"Age\"].median(skipna=True), inplace=True)\n",
    "train_data[\"Embarked\"].fillna(train_df['Embarked'].value_counts().idxmax(), inplace=True)\n",
    "train_data.drop('Cabin', axis=1, inplace=True)\n",
    "train_data['TravelAlone']=np.where((train_data[\"SibSp\"]+train_data[\"Parch\"])>0, 0, 1)\n",
    "train_data.drop('SibSp', axis=1, inplace=True)\n",
    "train_data.drop('Parch', axis=1, inplace=True)\n",
    "training=pd.get_dummies(train_data, columns=[\"Pclass\",\"Embarked\",\"Sex\"])#进行独热编码\n",
    "training.drop('Sex_female', axis=1, inplace=True)\n",
    "training.drop('PassengerId', axis=1, inplace=True)\n",
    "training.drop('Name', axis=1, inplace=True)\n",
    "training.drop('Ticket', axis=1, inplace=True)\n",
    "\n",
    "test_data = test_df.copy()\n",
    "test_data[\"Age\"].fillna(train_df[\"Age\"].median(skipna=True), inplace=True)\n",
    "test_data[\"Fare\"].fillna(train_df[\"Fare\"].median(skipna=True), inplace=True)\n",
    "test_data.drop('Cabin', axis=1, inplace=True)\n",
    "test_data['TravelAlone']=np.where((test_data[\"SibSp\"]+test_data[\"Parch\"])>0, 0, 1)\n",
    "test_data.drop('SibSp', axis=1, inplace=True)\n",
    "test_data.drop('Parch', axis=1, inplace=True)\n",
    "testing = pd.get_dummies(test_data, columns=[\"Pclass\",\"Embarked\",\"Sex\"])\n",
    "testing.drop('Sex_female', axis=1, inplace=True)\n",
    "testing.drop('PassengerId', axis=1, inplace=True)\n",
    "testing.drop('Name', axis=1, inplace=True)\n",
    "testing.drop('Ticket', axis=1, inplace=True)\n",
    "final_test = testing\n",
    "final_train = training\n",
    "\n",
    "final_train['IsMinor']=np.where(final_train['Age']<=16, 1, 0)\n",
    "final_test['IsMinor']=np.where(final_test['Age']<=16, 1, 0)\n",
    "\n",
    "final_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "together-narrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"Age\",\"Fare\",\"TravelAlone\",\"Pclass_1\",\"Pclass_2\",\"Embarked_C\",\"Embarked_S\",\"Sex_male\",\"IsMinor\"] \n",
    "X = final_train[cols]\n",
    "y = final_train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "handy-declaration",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-0ef73cb07e70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mrfc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mrfc_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrfc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0msuperpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrfc_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msuperpa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msuperpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msuperpa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    438\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n\u001b[0m\u001b[0;32m    441\u001b[0m                                 \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'score'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    244\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[0;32m    245\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[1;32m--> 246\u001b[1;33m     results = parallel(\n\u001b[0m\u001b[0;32m    247\u001b[0m         delayed(_fit_and_score)(\n\u001b[0;32m    248\u001b[0m             \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    591\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;31m# since correctness does not rely on using threads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m    388\u001b[0m                              \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'threads'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    432\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "superpa = []\n",
    "for i in range(200):\n",
    "    rfc = RandomForestClassifier(n_estimators=i+1,n_jobs=-1)\n",
    "    rfc_s = cross_val_score(rfc,X,y,cv=10).mean()\n",
    "    superpa.append(rfc_s)\n",
    "print(max(superpa),superpa.index(max(superpa)))\n",
    "plt.figure(figsize=[20,5])\n",
    "plt.plot(range(1,201),superpa)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-guest",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "superpa = []\n",
    "for i in range(200):\n",
    "    rfc = RandomForestClassifier(n_estimators=13,max_depth = i+1, n_jobs=-1)\n",
    "    rfc_s = cross_val_score(rfc,X,y,cv=10).mean()\n",
    "    superpa.append(rfc_s)\n",
    "print(max(superpa),superpa.index(max(superpa)))\n",
    "plt.figure(figsize=[20,5])\n",
    "plt.plot(range(1,201),superpa)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-burner",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "superpa = []\n",
    "for i in range(1000):\n",
    "    rfc = RandomForestClassifier(n_estimators=13,max_depth = 86, max_leaf_nodes = i+1)\n",
    "    rfc_s = cross_val_score(rfc,X,y,cv=10).mean()\n",
    "    superpa.append(rfc_s)\n",
    "print(max(superpa),superpa.index(max(superpa)))\n",
    "plt.figure(figsize=[20,5])\n",
    "plt.plot(range(1,1001),superpa)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-spray",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "param_grid={'min_samples_leaf':np.arange(1, 1+30, 1)\n",
    "           ,'min_samples_split':np.arange(2, 2+30, 1)\n",
    "           ,'criterion':['gini', 'entropy']\n",
    "           ,'max_features':np.arange(1,100,1)\n",
    "           ,'max_leaf_nodes': np.arange(1,200,1)}\n",
    "rfc = RandomForestClassifier(n_estimators=13,max_depth = 86,random_state = 0)\n",
    "GS = GridSearchCV(rfc,param_grid,cv=10)\n",
    "GS.fit(X,y)\n",
    "GS.best_params_\n",
    "GS.best_score_\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "classified-wellington",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state = 0\n",
    "                            ,n_estimators = 13\n",
    "                            ,max_depth = 86\n",
    "                            ,min_samples_leaf = 3\n",
    "                            ,min_samples_split = 10\n",
    "                            ,max_features = 7\n",
    "                            ,max_leaf_nodes = 55\n",
    "                            ,criterion = 'gini'\n",
    "                            )\n",
    "lr = LogisticRegression(C=4.1,random_state = 0)\n",
    "eclf1 = VotingClassifier(estimators=[('lr', lr), ('rf', rf)],voting = 'soft')\n",
    "eclf = eclf1.fit(X,y)\n",
    "rf = rf.fit(X,y)\n",
    "lr = lr.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "funny-delivery",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    \"\"\"Generate a library of base learners.\"\"\"\n",
    "   #nb = GaussianNB()\n",
    "   #svc = SVC(C=100, probability=True)\n",
    "   #knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    lr = LogisticRegression(C=4.1,random_state = 0)\n",
    "   #nn = MLPClassifier((80, 10), early_stopping=False, random_state=SEED)\n",
    "   #gb = GradientBoostingClassifier(n_estimators=100, random_state=SEED)\n",
    "    rf = RandomForestClassifier(random_state = 0\n",
    "                            ,n_estimators = 13\n",
    "                            ,max_depth = 86\n",
    "                            ,min_samples_leaf = 3\n",
    "                            ,min_samples_split = 10\n",
    "                            ,max_features = 7\n",
    "                            ,max_leaf_nodes = 55\n",
    "                            ,criterion = 'gini'\n",
    "                            )\n",
    "\n",
    "    models = {#'svm': svc,\n",
    "#'knn': knn,\n",
    "#'naive bayes': nb,\n",
    "#'mlp-nn': nn,\n",
    "'random forest': rf,\n",
    "#'gbm': gb,\n",
    "'logistic': lr,\n",
    "             }\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "demographic-coral",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_predict(model_list):\n",
    "    \"\"\"Fit models in list on training set and return preds\"\"\"\n",
    "    P = np.zeros((ytest.shape[0], len(model_list)))\n",
    "    P = pd.DataFrame(P)\n",
    "\n",
    "    print(\"Fitting models.\")\n",
    "    cols = list()\n",
    "    for i, (name, m) in enumerate(models.items()):\n",
    "        print(\"%s...\" % name, end=\" \", flush=False)\n",
    "        m.fit(xtrain, ytrain)\n",
    "        P.iloc[:, i] = m.predict_proba(xtest)[:, 1]\n",
    "        cols.append(name)\n",
    "    print(\"done\")\n",
    "    P.columns = cols\n",
    "    print(\"Done.\\n\")\n",
    "    return P\n",
    "\n",
    "\n",
    "def score_models(P, y):\n",
    "    \"\"\"Score model in prediction DF\"\"\"\n",
    "    print(\"Scoring models.\")\n",
    "    for m in P.columns:\n",
    "        score = roc_auc_score(y, P.loc[:, m])\n",
    "    print(\"%-26s: %.3f\" % (m, score))\n",
    "    print(\"Done.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "baking-research",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_learners = get_models()\n",
    "meta_learner = GradientBoostingClassifier(\n",
    "   n_estimators=1000,\n",
    "   loss=\"exponential\",\n",
    "   #max_features=4,\n",
    "   max_depth=3,\n",
    "   subsample=0.5,\n",
    "   learning_rate=0.005, \n",
    "   random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "crazy-brighton",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_base_learners(base_learners, inp, out, verbose=True):\n",
    "    \"\"\"Train all base learners in the library.\"\"\"\n",
    "    if verbose: print(\"Fitting models.\")\n",
    "    for i, (name, m) in enumerate(base_learners.items()):\n",
    "        if verbose: \n",
    "            print(\"%s...\" % name, end=\" \", flush=False)\n",
    "            m.fit(inp, out)\n",
    "        if verbose: \n",
    "            print(\"done\")\n",
    "\n",
    "def predict_base_learners(pred_base_learners, inp, verbose=True):\n",
    "    \"\"\"Generate a prediction matrix.\"\"\"\n",
    "    P = np.zeros((inp.shape[0], len(pred_base_learners)))\n",
    "    if verbose: \n",
    "        print(\"Generating base learner predictions.\")\n",
    "    for i, (name, m) in enumerate(pred_base_learners.items()):\n",
    "        if verbose: \n",
    "            print(\"%s...\" % name, end=\" \", flush=False)\n",
    "            p = m.predict_proba(inp)# With two classes, need only predictions for one class\n",
    "            P[:, i] = p[:, 1]\n",
    "        if verbose:\n",
    "            print(\"done\")\n",
    "    return P\n",
    "\n",
    "def ensemble_predict(base_learners, meta_learner, inp, verbose=True):\n",
    "    \"\"\"Generate predictions from the ensemble.\"\"\"\n",
    "    P_pred = predict_base_learners(base_learners, inp, verbose=verbose)\n",
    "    return P_pred, meta_learner.predict_proba(P_pred)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "technical-domestic",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "xtrain_base, xpred_base, ytrain_base, ypred_base = train_test_split(\n",
    "   X, y, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "allied-malta",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting models.\n",
      "random forest... done\n",
      "logistic... done\n"
     ]
    }
   ],
   "source": [
    "train_base_learners(base_learners, xtrain_base, ytrain_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "affected-spine",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating base learner predictions.\n",
      "random forest... done\n",
      "logistic... done\n"
     ]
    }
   ],
   "source": [
    "P_base = predict_base_learners(base_learners, xpred_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "unexpected-backup",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating base learner predictions.\n",
      "random forest... done\n",
      "logistic... done\n"
     ]
    }
   ],
   "source": [
    "meta_learner.fit(P_base, ypred_base)\n",
    "P_pred, p = ensemble_predict(base_learners, meta_learner, final_test[cols])\n",
    "#print(\"\\nEnsemble ROC-AUC score: %.3f\" % roc_auc_score(rf.predict(final_test[cols]), p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "broken-gabriel",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15703186, 0.142315  ],\n",
       "       [0.19846329, 0.44941786],\n",
       "       [0.06783217, 0.18587876],\n",
       "       [0.34830725, 0.08823647],\n",
       "       [0.82921523, 0.59761491],\n",
       "       [0.26007326, 0.1575024 ],\n",
       "       [0.67252471, 0.68775687],\n",
       "       [0.08550296, 0.232666  ],\n",
       "       [0.83985961, 0.73384181],\n",
       "       [0.03525641, 0.1140828 ],\n",
       "       [0.01398601, 0.08629195],\n",
       "       [0.23925647, 0.32107611],\n",
       "       [0.93333333, 0.92089399],\n",
       "       [0.02457265, 0.11154223],\n",
       "       [1.        , 0.86603184],\n",
       "       [0.98076923, 0.87974715],\n",
       "       [0.13760534, 0.30297698],\n",
       "       [0.1260355 , 0.17709209],\n",
       "       [0.3890477 , 0.56783284],\n",
       "       [0.42204377, 0.59208951],\n",
       "       [0.38441558, 0.46342964],\n",
       "       [0.34567484, 0.19257738],\n",
       "       [0.83928571, 0.89686012],\n",
       "       [0.34566056, 0.65994896],\n",
       "       [0.84387386, 0.93532257],\n",
       "       [0.03525641, 0.06025523],\n",
       "       [1.        , 0.95766566],\n",
       "       [0.1260355 , 0.17195734],\n",
       "       [0.71144454, 0.34837461],\n",
       "       [0.45407413, 0.17360289],\n",
       "       [0.02457265, 0.1460192 ],\n",
       "       [0.04487179, 0.24164769],\n",
       "       [0.64151959, 0.53524051],\n",
       "       [0.43556444, 0.56523936],\n",
       "       [0.40859762, 0.60971579],\n",
       "       [0.15167653, 0.18591663],\n",
       "       [0.4811223 , 0.52982507],\n",
       "       [0.63252645, 0.57109027],\n",
       "       [0.        , 0.09219506],\n",
       "       [0.31344   , 0.08960658],\n",
       "       [0.20147481, 0.13839094],\n",
       "       [0.50093011, 0.42052048],\n",
       "       [0.13675214, 0.06484412],\n",
       "       [0.83548265, 0.74023601],\n",
       "       [1.        , 0.87062701],\n",
       "       [0.08547009, 0.09208302],\n",
       "       [0.39814502, 0.48398322],\n",
       "       [0.18740437, 0.16221964],\n",
       "       [0.9284188 , 0.8907259 ],\n",
       "       [0.6701826 , 0.51647731],\n",
       "       [0.32426017, 0.48319967],\n",
       "       [0.5149197 , 0.33158156],\n",
       "       [1.        , 0.80584598],\n",
       "       [0.74314126, 0.9233974 ],\n",
       "       [0.472612  , 0.32643824],\n",
       "       [0.1529304 , 0.32806548],\n",
       "       [0.06495726, 0.07404774],\n",
       "       [0.        , 0.09206348],\n",
       "       [0.10951677, 0.0977144 ],\n",
       "       [0.8790387 , 0.94410242],\n",
       "       [0.00854701, 0.10925372],\n",
       "       [0.40527379, 0.18558   ],\n",
       "       [0.05470085, 0.10695075],\n",
       "       [0.94280079, 0.72707551],\n",
       "       [0.54233203, 0.797884  ],\n",
       "       [0.81426776, 0.75054544],\n",
       "       [0.85909038, 0.74554974],\n",
       "       [0.31028672, 0.31893993],\n",
       "       [0.36412802, 0.56650318],\n",
       "       [0.81670658, 0.84928791],\n",
       "       [0.88333803, 0.71754802],\n",
       "       [0.        , 0.1003414 ],\n",
       "       [0.56523818, 0.52387514],\n",
       "       [0.40258956, 0.5808613 ],\n",
       "       [0.8790387 , 0.94306446],\n",
       "       [0.52579856, 0.59568926],\n",
       "       [0.05599956, 0.08630229],\n",
       "       [0.72909035, 0.83835691],\n",
       "       [0.21162299, 0.19280434],\n",
       "       [0.88333803, 0.71754802],\n",
       "       [0.6852848 , 0.33315258],\n",
       "       [0.40660984, 0.27859359],\n",
       "       [0.23925647, 0.30573851],\n",
       "       [0.01398601, 0.08629195],\n",
       "       [0.15517378, 0.33889559],\n",
       "       [0.45703271, 0.17272325],\n",
       "       [0.87721617, 0.7029016 ],\n",
       "       [0.58727758, 0.58833041],\n",
       "       [0.84743313, 0.69789227],\n",
       "       [0.54062882, 0.43067928],\n",
       "       [0.82921523, 0.5979446 ],\n",
       "       [0.08978244, 0.08628385],\n",
       "       [0.96153846, 0.9116354 ],\n",
       "       [0.05599956, 0.08630229],\n",
       "       [0.26581864, 0.60061201],\n",
       "       [0.06431624, 0.09207384],\n",
       "       [0.9284188 , 0.7671406 ],\n",
       "       [0.30853591, 0.08443862],\n",
       "       [0.76609288, 0.57673295],\n",
       "       [0.08591409, 0.07738233],\n",
       "       [1.        , 0.931778  ],\n",
       "       [0.07588757, 0.22800125],\n",
       "       [0.18740437, 0.16221964],\n",
       "       [0.17065029, 0.09010509],\n",
       "       [0.66842634, 0.82372297],\n",
       "       [0.10853804, 0.08727784],\n",
       "       [0.06803613, 0.18612222],\n",
       "       [0.18740437, 0.16221964],\n",
       "       [0.33923427, 0.08634672],\n",
       "       [0.07264957, 0.23891798],\n",
       "       [0.22169625, 0.2623663 ],\n",
       "       [0.87721617, 0.6978975 ],\n",
       "       [0.92948718, 0.93280158],\n",
       "       [0.85909038, 0.74319253],\n",
       "       [0.81670658, 0.83516543],\n",
       "       [0.49080983, 0.2093541 ],\n",
       "       [0.1510355 , 0.15405014],\n",
       "       [0.72523343, 0.77683932],\n",
       "       [0.58985801, 0.54698597],\n",
       "       [0.93656344, 0.77064006],\n",
       "       [0.754884  , 0.86132021],\n",
       "       [0.1957377 , 0.18065909],\n",
       "       [1.        , 0.94302019],\n",
       "       [0.02637363, 0.08624866],\n",
       "       [0.18740437, 0.16221964],\n",
       "       [0.7275561 , 0.62658446],\n",
       "       [0.06431624, 0.09820904],\n",
       "       [0.65876068, 0.72718315],\n",
       "       [0.18842952, 0.15225271],\n",
       "       [0.01404151, 0.09409807],\n",
       "       [0.48382728, 0.07909597],\n",
       "       [0.40899314, 0.43654158],\n",
       "       [0.43556444, 0.56566073],\n",
       "       [0.20744576, 0.17175134],\n",
       "       [0.07264957, 0.06202341],\n",
       "       [0.        , 0.09408388],\n",
       "       [0.17988166, 0.15884214],\n",
       "       [0.15935987, 0.2080302 ],\n",
       "       [0.65816747, 0.55928354],\n",
       "       [0.00854701, 0.07714095],\n",
       "       [0.31193529, 0.74252978],\n",
       "       [0.8790387 , 0.89528773],\n",
       "       [0.35680708, 0.47090293],\n",
       "       [0.07125994, 0.20208549],\n",
       "       [0.61923675, 0.34224337],\n",
       "       [0.3945595 , 0.0917415 ],\n",
       "       [0.2716184 , 0.42577438],\n",
       "       [0.01404151, 0.09822818],\n",
       "       [0.50093011, 0.42052048],\n",
       "       [0.13091716, 0.21569722],\n",
       "       [0.98461538, 0.95743181],\n",
       "       [0.19640712, 0.15421182],\n",
       "       [0.03205128, 0.04202806],\n",
       "       [0.55479798, 0.51568801],\n",
       "       [0.01739927, 0.18176937],\n",
       "       [0.        , 0.09406184],\n",
       "       [0.82775665, 0.90893484],\n",
       "       [0.79173391, 0.5592425 ],\n",
       "       [0.61923675, 0.34224337],\n",
       "       [0.57384282, 0.57487068],\n",
       "       [0.84743313, 0.69788928],\n",
       "       [0.71092583, 0.32789454],\n",
       "       [0.78862673, 0.7581697 ],\n",
       "       [0.12509158, 0.08623191],\n",
       "       [0.18842952, 0.1553452 ],\n",
       "       [0.54133367, 0.57658428],\n",
       "       [0.33681532, 0.47061063],\n",
       "       [0.03525641, 0.12241933],\n",
       "       [0.82738095, 0.94360234],\n",
       "       [0.86410256, 0.56532284],\n",
       "       [0.02637363, 0.08626877],\n",
       "       [0.2183432 , 0.1572611 ],\n",
       "       [0.04487179, 0.10852081],\n",
       "       [0.13994083, 0.1541379 ],\n",
       "       [0.07448107, 0.07620711],\n",
       "       [0.88547009, 0.8704223 ],\n",
       "       [0.84123932, 0.78667809],\n",
       "       [0.48154068, 0.46850513],\n",
       "       [0.85500056, 0.74204897],\n",
       "       [0.9284188 , 0.8946253 ],\n",
       "       [0.21162299, 0.19280434],\n",
       "       [0.55034453, 0.57478121],\n",
       "       [1.        , 0.92747719],\n",
       "       [0.18740437, 0.16221964],\n",
       "       [0.79442331, 0.95921738],\n",
       "       [0.09648258, 0.15882928],\n",
       "       [0.91669719, 0.80183099],\n",
       "       [0.11438668, 0.12256737],\n",
       "       [0.39655067, 0.57484692],\n",
       "       [0.18842952, 0.15848875],\n",
       "       [0.02457265, 0.20005195],\n",
       "       [0.24639362, 0.42040652],\n",
       "       [0.32516202, 0.18495634],\n",
       "       [0.08599456, 0.18984955],\n",
       "       [0.0740232 , 0.39805465],\n",
       "       [0.12905983, 0.07737044],\n",
       "       [0.62796648, 0.80701373],\n",
       "       [0.72084401, 0.58827377],\n",
       "       [0.03076923, 0.21965497],\n",
       "       [0.4811223 , 0.52983831],\n",
       "       [0.90724811, 0.69927992],\n",
       "       [0.65272612, 0.22832751],\n",
       "       [0.53473684, 0.54649563],\n",
       "       [0.83223443, 0.88695229],\n",
       "       [0.03076923, 0.21161745],\n",
       "       [0.28120325, 0.58334215],\n",
       "       [0.556647  , 0.66171432],\n",
       "       [0.03076923, 0.21560905],\n",
       "       [0.87179487, 0.93693597],\n",
       "       [0.        , 0.09208095],\n",
       "       [0.45439091, 0.07999719],\n",
       "       [0.05201465, 0.08623526],\n",
       "       [0.18919969, 0.25511201],\n",
       "       [0.53451826, 0.61663498],\n",
       "       [0.25290884, 0.50287471],\n",
       "       [0.51574366, 0.34530307],\n",
       "       [0.87721617, 0.69791543],\n",
       "       [0.40660984, 0.31816486],\n",
       "       [0.8374636 , 0.92960861],\n",
       "       [0.05599956, 0.08630229],\n",
       "       [0.86783131, 0.86243635],\n",
       "       [0.01404151, 0.10035324],\n",
       "       [0.84957265, 0.77472219],\n",
       "       [0.06431624, 0.10033373],\n",
       "       [0.68421856, 0.90229418],\n",
       "       [0.8084296 , 0.71367706],\n",
       "       [0.06431624, 0.09612453],\n",
       "       [0.84743313, 0.69789227],\n",
       "       [0.17488494, 0.06594707],\n",
       "       [0.16919875, 0.17158072],\n",
       "       [0.19377844, 0.34109176],\n",
       "       [0.83653846, 0.91090915],\n",
       "       [0.11025641, 0.11257432],\n",
       "       [0.10519769, 0.16223458],\n",
       "       [0.60803683, 0.56064069],\n",
       "       [0.01709402, 0.10250373],\n",
       "       [0.27100122, 0.41412753],\n",
       "       [0.1260355 , 0.18058163],\n",
       "       [0.88464591, 0.81187848],\n",
       "       [1.        , 0.92682209],\n",
       "       [0.68421856, 0.89804496],\n",
       "       [0.43790654, 0.69743841],\n",
       "       [0.53473684, 0.53865851],\n",
       "       [0.01398601, 0.08629139],\n",
       "       [0.0443787 , 0.09826683],\n",
       "       [0.41064833, 0.38269858],\n",
       "       [0.88162393, 0.77627666],\n",
       "       [0.09050672, 0.17213901],\n",
       "       [0.93656344, 0.77064006],\n",
       "       [0.64826477, 0.71353949],\n",
       "       [0.8989011 , 0.90288578],\n",
       "       [0.1025641 , 0.10250927],\n",
       "       [0.36334435, 0.64212687],\n",
       "       [0.        , 0.09419053],\n",
       "       [0.49315129, 0.07832382],\n",
       "       [0.02637363, 0.08626877],\n",
       "       [0.18740437, 0.16221964],\n",
       "       [0.05599956, 0.08630229],\n",
       "       [0.82393162, 0.78727606],\n",
       "       [0.05470085, 0.10033213],\n",
       "       [0.05695266, 0.08137885],\n",
       "       [0.        , 0.10033821],\n",
       "       [0.93656344, 0.77018885],\n",
       "       [0.76287079, 0.77617278],\n",
       "       [0.35200761, 0.31555388],\n",
       "       [0.01398601, 0.08629195],\n",
       "       [0.16645966, 0.41502903],\n",
       "       [0.02637363, 0.08626877],\n",
       "       [0.4811223 , 0.52982507],\n",
       "       [0.02942613, 0.10931719],\n",
       "       [0.42286261, 0.4877211 ],\n",
       "       [0.18740437, 0.16221964],\n",
       "       [0.91538462, 0.95637233],\n",
       "       [0.81434676, 0.72587378],\n",
       "       [0.12218935, 0.15413743],\n",
       "       [1.        , 0.8062448 ],\n",
       "       [0.12944534, 0.19996855],\n",
       "       [0.02457265, 0.17820667],\n",
       "       [0.13091716, 0.21497882],\n",
       "       [0.03076923, 0.22375515],\n",
       "       [0.63252645, 0.55941192],\n",
       "       [0.65272612, 0.2264807 ],\n",
       "       [0.84743313, 0.69789227],\n",
       "       [0.67163147, 0.84733336],\n",
       "       [0.46070351, 0.77321694],\n",
       "       [0.00512821, 0.07239798],\n",
       "       [0.02637363, 0.08624866],\n",
       "       [0.19281808, 0.48792928],\n",
       "       [0.13994083, 0.1541379 ],\n",
       "       [0.05599956, 0.08630229],\n",
       "       [0.2716184 , 0.42322699],\n",
       "       [0.67252471, 0.68763283],\n",
       "       [0.13994083, 0.1541379 ],\n",
       "       [0.31589351, 0.32349555],\n",
       "       [0.11045365, 0.07252657],\n",
       "       [0.10126412, 0.09011351],\n",
       "       [0.83931624, 0.94771775],\n",
       "       [0.45407413, 0.17360289],\n",
       "       [0.2716184 , 0.41288582],\n",
       "       [0.25127095, 0.08443396],\n",
       "       [0.320116  , 0.07907894],\n",
       "       [0.472612  , 0.32633851],\n",
       "       [0.01602564, 0.16741154],\n",
       "       [0.0486569 , 0.09414248],\n",
       "       [0.84743313, 0.69789227],\n",
       "       [0.72909035, 0.80735478],\n",
       "       [0.43040549, 0.46705953],\n",
       "       [0.65272612, 0.22549001],\n",
       "       [0.33386165, 0.3153166 ],\n",
       "       [0.276776  , 0.46270603],\n",
       "       [0.02942613, 0.10702489],\n",
       "       [0.1260355 , 0.17365569],\n",
       "       [0.02637363, 0.08627044],\n",
       "       [0.556647  , 0.65099554],\n",
       "       [0.97115385, 0.90614522],\n",
       "       [0.84370577, 0.75000801],\n",
       "       [0.35680708, 0.47003954],\n",
       "       [0.12905983, 0.2363803 ],\n",
       "       [0.1781872 , 0.08818119],\n",
       "       [0.04487179, 0.25046344],\n",
       "       [0.17065029, 0.09010509],\n",
       "       [0.14378698, 0.16366316],\n",
       "       [0.15935987, 0.2080302 ],\n",
       "       [0.52912414, 0.39187205],\n",
       "       [0.85156617, 0.88637066],\n",
       "       [0.02564103, 0.09606944],\n",
       "       [0.79462759, 0.87825256],\n",
       "       [0.3651703 , 0.4885621 ],\n",
       "       [0.10014793, 0.21974433],\n",
       "       [0.        , 0.22828381],\n",
       "       [0.65268065, 0.68343036],\n",
       "       [0.53308913, 0.51961151],\n",
       "       [0.12218935, 0.15413743],\n",
       "       [0.8707265 , 0.75539477],\n",
       "       [0.13972566, 0.08818403],\n",
       "       [0.24639362, 0.40887212],\n",
       "       [0.43622617, 0.18551575],\n",
       "       [0.09991483, 0.13776476],\n",
       "       [0.06593407, 0.21461201],\n",
       "       [0.13994083, 0.1541379 ],\n",
       "       [0.11196581, 0.24069638],\n",
       "       [0.26755189, 0.07906681],\n",
       "       [0.17553088, 0.10179555],\n",
       "       [0.81670658, 0.93378879],\n",
       "       [0.13515779, 0.09759451],\n",
       "       [0.7054594 , 0.67989543],\n",
       "       [0.15935987, 0.2080302 ],\n",
       "       [0.49805109, 0.63156848],\n",
       "       [0.        , 0.2160408 ],\n",
       "       [0.83548265, 0.7369616 ],\n",
       "       [1.        , 0.92913874],\n",
       "       [0.03076923, 0.21161745],\n",
       "       [0.18919969, 0.25062275],\n",
       "       [0.14421134, 0.15326172],\n",
       "       [0.46070351, 0.78080428],\n",
       "       [0.23925647, 0.30071802],\n",
       "       [0.97115385, 0.82820006],\n",
       "       [0.01398601, 0.08629083],\n",
       "       [0.18740437, 0.16221964],\n",
       "       [0.6701826 , 0.55186547],\n",
       "       [0.18523144, 0.18129503],\n",
       "       [0.86623932, 0.88057978],\n",
       "       [0.83548265, 0.7369616 ],\n",
       "       [0.34830725, 0.08823647],\n",
       "       [0.96153846, 0.95443821],\n",
       "       [0.39655067, 0.57484692],\n",
       "       [0.45703271, 0.17272374],\n",
       "       [0.56944444, 0.57173175],\n",
       "       [1.        , 0.92891681],\n",
       "       [0.39376585, 0.32091613],\n",
       "       [0.04487179, 0.25173383],\n",
       "       [1.        , 0.94463174],\n",
       "       [0.2471236 , 0.30106587],\n",
       "       [0.12186147, 0.1462194 ],\n",
       "       [0.97115385, 0.84781551],\n",
       "       [0.89002771, 0.93168405],\n",
       "       [0.60859482, 0.59687344],\n",
       "       [0.        , 0.22805918],\n",
       "       [0.27609869, 0.2804389 ],\n",
       "       [0.2723138 , 0.21176734],\n",
       "       [0.18740437, 0.16221964],\n",
       "       [0.1614107 , 0.16879805],\n",
       "       [0.58098568, 0.53119115],\n",
       "       [0.83306138, 0.61539953],\n",
       "       [0.11268005, 0.20029184],\n",
       "       [0.87148407, 0.79639364],\n",
       "       [0.05470085, 0.09407814],\n",
       "       [0.10476745, 0.11170135],\n",
       "       [0.12273699, 0.1861131 ],\n",
       "       [0.38678266, 0.206388  ],\n",
       "       [0.32753913, 0.46383978],\n",
       "       [0.94551282, 0.85229971],\n",
       "       [0.20879121, 0.18036505],\n",
       "       [0.04667832, 0.13729043],\n",
       "       [0.13155819, 0.09607594],\n",
       "       [1.        , 0.92787086],\n",
       "       [0.03796844, 0.17549399],\n",
       "       [1.        , 0.92523635],\n",
       "       [0.05470085, 0.09820747],\n",
       "       [0.23757332, 0.15276121],\n",
       "       [0.82775665, 0.90278332],\n",
       "       [0.01602564, 0.18463249],\n",
       "       [1.        , 0.95757666],\n",
       "       [0.31124543, 0.48955791],\n",
       "       [0.4775007 , 0.52788836],\n",
       "       [0.31565934, 0.36918884],\n",
       "       [0.07564103, 0.24273151],\n",
       "       [0.45071318, 0.52537991],\n",
       "       [0.84743313, 0.69788703],\n",
       "       [0.76287079, 0.76804931],\n",
       "       [0.84743313, 0.69789227],\n",
       "       [1.        , 0.94514009],\n",
       "       [0.59087921, 0.52976682],\n",
       "       [0.05599956, 0.08630229],\n",
       "       [0.96153846, 0.93244823],\n",
       "       [0.00512821, 0.0685084 ],\n",
       "       [0.05599956, 0.08630229],\n",
       "       [0.45407413, 0.17368575]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "sensitive-genealogy",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p_predproba = 0.5*(rf.predict_proba(final_test[cols]) + rf.predict_proba(final_test[cols]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "coastal-differential",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_pred = []\n",
    "for i in p_predproba:\n",
    "    if i[0]>=i[1]:\n",
    "        p_pred.append(0)\n",
    "    else:\n",
    "        p_pred.append(1)\n",
    "        \n",
    "p_pred = np.array(p_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "decent-choice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test['Survived'] = eclf.predict(final_test[cols])\n",
    "final_test['PassengerId'] = test_df['PassengerId']\n",
    "\n",
    "submission = final_test[['PassengerId','Survived']]\n",
    "submission.to_csv(\"submission1.csv\", index=False)\n",
    "submission.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-grove",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-confusion",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
