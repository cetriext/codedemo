{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2c6a8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88f85a7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key1 key2     data1     data2\n",
      "0    a  one  1.129234  0.651835\n",
      "1    b  two -1.421035  1.603570\n",
      "2    a  one  2.290581 -0.756843\n",
      "3    b  two -1.590281  1.766254\n",
      "4    a  one  0.882883  0.042699\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'key1':list('ababa'),\n",
    "                  'key2': ['one','two','one','two','one'],\n",
    "                  'data1': np.random.randn(5),\n",
    "                  'data2': np.random.randn(5)})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e58ce95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a',\n",
       "  0    1.129234\n",
       "  2    2.290581\n",
       "  4    0.882883\n",
       "  Name: data1, dtype: float64),\n",
       " ('b',\n",
       "  1   -1.421035\n",
       "  3   -1.590281\n",
       "  Name: data1, dtype: float64)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped=df['data1'].groupby(df['key1'])\n",
    "list(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61bff989",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key1\n",
      "a    1.434233\n",
      "b   -1.505658\n",
      "Name: data1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(grouped.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a49902b0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "states=np.array(['Ohio','California','California','Ohio','Ohio'])\n",
    "years=np.array([2005,2005,2006,2005,2006])\n",
    "#states第一层索引，years第二层分层索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1a75b96",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005  California   -1.421035\n",
      "      Ohio         -0.230524\n",
      "2006  California    2.290581\n",
      "      Ohio          0.882883\n",
      "Name: data1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df['data1'].groupby([years,states]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92ae8a29",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>1.434233</td>\n",
       "      <td>-0.020770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>-1.505658</td>\n",
       "      <td>1.684912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         data1     data2\n",
       "key1                    \n",
       "a     1.434233 -0.020770\n",
       "b    -1.505658  1.684912"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('key1').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7815fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#输入必须是pandas\n",
    "def mean_woe_target_encoder(train,test,target,col,n_splits=10):\n",
    "    folds = StratifiedKFold(n_splits)\n",
    "\n",
    "    y_oof = np.zeros(train.shape[0])\n",
    "    y_oof_2= np.zeros(train.shape[0])\n",
    "    y_test_oof = np.zeros(test.shape[0]).reshape(-1,1)\n",
    "    y_test_oof2 = np.zeros(test.shape[0]).reshape(-1,1)\n",
    "\n",
    "    splits = folds.split(train, target)\n",
    "    \n",
    "    for fold_n, (train_index, valid_index) in enumerate(splits):\n",
    "        X_train, X_valid = train[col].iloc[train_index], train[col].iloc[valid_index]\n",
    "        y_train, y_valid = target.iloc[train_index], target.iloc[valid_index]\n",
    "        clf=ce.target_encoder.TargetEncoder()\n",
    "    \n",
    "    #    dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "    #    dvalid = lgb.Dataset(X_valid, label=y_valid)\n",
    "    \n",
    "        #clf = lgb.train(params, dtrain, 10000, valid_sets = [dtrain, dvalid], verbose_eval=1, early_stopping_rounds=500)\n",
    "        clf.fit(X_train.values,y_train.values)    \n",
    "        y_pred_valid = clf.transform(X_valid.values)\n",
    "        y_oof[valid_index] = y_pred_valid.values.reshape(1,-1)\n",
    "\n",
    "        tp=(clf.transform(test[col].values)/(n_splits*1.0)).values\n",
    "        tp=tp.reshape(-1,1)\n",
    "        y_test_oof+=tp    \n",
    "    \n",
    "        del X_train, X_valid, y_train, y_valid\n",
    "        gc.collect()    \n",
    "        \n",
    "    for fold_n, (train_index, valid_index) in enumerate(splits):\n",
    "        X_train, X_valid = train[col].iloc[train_index], train[col].iloc[valid_index]\n",
    "        y_train, y_valid = target.iloc[train_index], target.iloc[valid_index]\n",
    "        clf=ce.woe.WOEEncoder()\n",
    "    \n",
    "    #    dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "    #    dvalid = lgb.Dataset(X_valid, label=y_valid)\n",
    "    \n",
    "        #clf = lgb.train(params, dtrain, 10000, valid_sets = [dtrain, dvalid], verbose_eval=1, early_stopping_rounds=500)\n",
    "        clf.fit(X_train.values,y_train.values)    \n",
    "        y_pred_valid = clf.transform(X_valid.values)\n",
    "        y_oof2[valid_index] = y_pred_valid.values.reshape(1,-1)\n",
    "    \n",
    "        tp=(clf.transform(test[col].values)/(n_splits*1.0)).values\n",
    "        tp=tp.reshape(-1,1)\n",
    "        y_test_oof2+=tp    \n",
    "        del X_train, X_valid, y_train, y_valid\n",
    "        gc.collect()     \n",
    "    return y_oof,y_oof_2,y_test_oof,y_test_oof2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6115cfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e94b7f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame({'key1':list('ababa'),\n",
    "                        'key2': ['one','two','one','two','one'],\n",
    "                        'street_address': ['ac','ws','sd','qwed','wefQEW'],\n",
    "                        'data1': np.random.randn(5),\n",
    "                        'data2': np.random.randn(5)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a268a1b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key1</th>\n",
       "      <th>key2</th>\n",
       "      <th>street_address</th>\n",
       "      <th>data1</th>\n",
       "      <th>data2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>ac</td>\n",
       "      <td>0.042363</td>\n",
       "      <td>-0.360161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>ws</td>\n",
       "      <td>-1.314928</td>\n",
       "      <td>-0.478044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>sd</td>\n",
       "      <td>0.542726</td>\n",
       "      <td>1.643066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>qwed</td>\n",
       "      <td>-1.866147</td>\n",
       "      <td>-0.027763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>wefQEW</td>\n",
       "      <td>0.393950</td>\n",
       "      <td>0.257604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  key1  key2 street_address     data1     data2\n",
       "0    a     0             ac  0.042363 -0.360161\n",
       "1    b     1             ws -1.314928 -0.478044\n",
       "2    a     0             sd  0.542726  1.643066\n",
       "3    b     1           qwed -1.866147 -0.027763\n",
       "4    a     0         wefQEW  0.393950  0.257604"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2863874b",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "data_df['key2'] = le.fit_transform(data_df['key2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81e7256b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['one'],\n",
       "       ['two'],\n",
       "       ['one'],\n",
       "       ['two'],\n",
       "       ['one']], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = OneHotEncoder(categories='auto'\n",
    "                    #,n_values='auto'\n",
    "                    #, categorical_features='all'\n",
    "                    , dtype=np.float64\n",
    "                    , sparse=True\n",
    "                    , handle_unknown='error'\n",
    "                   )\n",
    "ac = np.array(data_df['key2']).reshape(-1,1)\n",
    "ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d45d8910",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_matrix = ohe.fit_transform(ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "acd3c5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1.0\n",
      "  (0, 1)\t1.0\n",
      "  (0, 0)\t1.0\n",
      "  (0, 1)\t1.0\n",
      "  (0, 0)\t1.0\n"
     ]
    }
   ],
   "source": [
    "for i in one_hot_matrix:\n",
    "    print(i)\n",
    "#    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7398671",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean_encoder 方法\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from itertools import product\n",
    "\n",
    "class MeanEncoder:\n",
    "    def __init__(self, categorical_features, n_splits=5, target_type='classification', prior_weight_func=None):\n",
    "        \"\"\"\n",
    "        :param categorical_features: list of str, the name of the categorical columns to encode\n",
    "\n",
    "        :param n_splits: the number of splits used in mean encoding\n",
    "\n",
    "        :param target_type: str, 'regression' or 'classification'\n",
    "\n",
    "        :param prior_weight_func:\n",
    "        a function that takes in the number of observations, and outputs prior weight\n",
    "        when a dict is passed, the default exponential decay function will be used:\n",
    "        k: the number of observations needed for the posterior to be weighted equally as the prior\n",
    "        f: larger f --> smaller slope\n",
    "        \"\"\"\n",
    "\n",
    "        self.categorical_features = categorical_features\n",
    "        self.n_splits = n_splits\n",
    "        self.learned_stats = {}\n",
    "\n",
    "        if target_type == 'classification':\n",
    "            self.target_type = target_type\n",
    "            self.target_values = []\n",
    "        else:\n",
    "            self.target_type = 'regression'\n",
    "            self.target_values = None\n",
    "\n",
    "        if isinstance(prior_weight_func, dict):\n",
    "            self.prior_weight_func = eval('lambda x: 1 / (1 + np.exp((x - k) / f))', dict(prior_weight_func, np=np))\n",
    "        elif callable(prior_weight_func):\n",
    "            self.prior_weight_func = prior_weight_func\n",
    "        else:\n",
    "            self.prior_weight_func = lambda x: 1 / (1 + np.exp((x - 2) / 1))\n",
    "\n",
    "    @staticmethod\n",
    "    def mean_encode_subroutine(X_train, y_train, X_test, variable, target, prior_weight_func):\n",
    "        X_train = X_train[[variable]].copy()\n",
    "        X_test = X_test[[variable]].copy()\n",
    "\n",
    "        if target is not None:\n",
    "            nf_name = '{}_pred_{}'.format(variable, target)\n",
    "            X_train['pred_temp'] = (y_train == target).astype(int)  # classification\n",
    "        else:\n",
    "            nf_name = '{}_pred'.format(variable)\n",
    "            X_train['pred_temp'] = y_train  # regression\n",
    "        prior = X_train['pred_temp'].mean()\n",
    "\n",
    "        col_avg_y = X_train.groupby(by=variable, axis=0)['pred_temp'].agg({'mean': 'mean', 'beta': 'size'})\n",
    "        col_avg_y['beta'] = prior_weight_func(col_avg_y['beta'])\n",
    "        col_avg_y[nf_name] = col_avg_y['beta'] * prior + (1 - col_avg_y['beta']) * col_avg_y['mean']\n",
    "        col_avg_y.drop(['beta', 'mean'], axis=1, inplace=True)\n",
    "\n",
    "        nf_train = X_train.join(col_avg_y, on=variable)[nf_name].values\n",
    "        nf_test = X_test.join(col_avg_y, on=variable).fillna(prior, inplace=False)[nf_name].values\n",
    "\n",
    "        return nf_train, nf_test, prior, col_avg_y\n",
    "\n",
    "    def fit_transform(self, X, y):\n",
    "        \"\"\"\n",
    "        :param X: pandas DataFrame, n_samples * n_features\n",
    "        :param y: pandas Series or numpy array, n_samples\n",
    "        :return X_new: the transformed pandas DataFrame containing mean-encoded categorical features\n",
    "        \"\"\"\n",
    "        X_new = X.copy()\n",
    "        if self.target_type == 'classification':\n",
    "            skf = StratifiedKFold(self.n_splits)\n",
    "        else:\n",
    "            skf = KFold(self.n_splits)\n",
    "\n",
    "        if self.target_type == 'classification':\n",
    "            self.target_values = sorted(set(y))\n",
    "            self.learned_stats = {'{}_pred_{}'.format(variable, target): [] for variable, target in\n",
    "                                  product(self.categorical_features, self.target_values)}\n",
    "            for variable, target in product(self.categorical_features, self.target_values):\n",
    "                nf_name = '{}_pred_{}'.format(variable, target)\n",
    "                X_new.loc[:, nf_name] = np.nan\n",
    "                for large_ind, small_ind in skf.split(y, y):\n",
    "                    nf_large, nf_small, prior, col_avg_y = MeanEncoder.mean_encode_subroutine(\n",
    "                        X_new.iloc[large_ind], y.iloc[large_ind], X_new.iloc[small_ind], variable, target, self.prior_weight_func)\n",
    "                    X_new.iloc[small_ind, -1] = nf_small\n",
    "                    self.learned_stats[nf_name].append((prior, col_avg_y))\n",
    "        else:\n",
    "            self.learned_stats = {'{}_pred'.format(variable): [] for variable in self.categorical_features}\n",
    "            for variable in self.categorical_features:\n",
    "                nf_name = '{}_pred'.format(variable)\n",
    "                X_new.loc[:, nf_name] = np.nan\n",
    "                for large_ind, small_ind in skf.split(y, y):\n",
    "                    nf_large, nf_small, prior, col_avg_y = MeanEncoder.mean_encode_subroutine(\n",
    "                        X_new.iloc[large_ind], y.iloc[large_ind], X_new.iloc[small_ind], variable, None, self.prior_weight_func)\n",
    "                    X_new.iloc[small_ind, -1] = nf_small\n",
    "                    self.learned_stats[nf_name].append((prior, col_avg_y))\n",
    "        return X_new\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        :param X: pandas DataFrame, n_samples * n_features\n",
    "        :return X_new: the transformed pandas DataFrame containing mean-encoded categorical features\n",
    "        \"\"\"\n",
    "        X_new = X.copy()\n",
    "\n",
    "        if self.target_type == 'classification':\n",
    "            for variable, target in product(self.categorical_features, self.target_values):\n",
    "                nf_name = '{}_pred_{}'.format(variable, target)\n",
    "                X_new[nf_name] = 0\n",
    "                for prior, col_avg_y in self.learned_stats[nf_name]:\n",
    "                    X_new[nf_name] += X_new[[variable]].join(col_avg_y, on=variable).fillna(prior, inplace=False)[\n",
    "                        nf_name]\n",
    "                X_new[nf_name] /= self.n_splits\n",
    "        else:\n",
    "            for variable in self.categorical_features:\n",
    "                nf_name = '{}_pred'.format(variable)\n",
    "                X_new[nf_name] = 0\n",
    "                for prior, col_avg_y in self.learned_stats[nf_name]:\n",
    "                    X_new[nf_name] += X_new[[variable]].join(col_avg_y, on=variable).fillna(prior, inplace=False)[\n",
    "                        nf_name]\n",
    "                X_new[nf_name] /= self.n_splits\n",
    "\n",
    "        return X_new"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
